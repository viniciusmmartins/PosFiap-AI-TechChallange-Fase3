{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusmmartins/PosFiap-AI-TechChallange-Fase3/blob/main/Tech_Challange_fase3_Gemma_4B_unsloth_bnb_4bit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**negrito** Fine-tuning de LLM com dados mÃ©dicos internos (âœ…)\n",
        "\n",
        "    [X] Realizar o fine-tuning de um modelo LLM (como LLaMA, Falcon ou outro) utilizando:\n",
        "        Protocolos mÃ©dicos do hospital\n",
        "        Exemplos de perguntas frequentes feitas por mÃ©dicos\n",
        "        Modelos de laudos, receitas e procedimentos internos\n",
        "    Preparar os dados com tÃ©cnicas de preprocessing, anonimizaÃ§Ã£o e curadoria\n",
        "    Aulas:\n",
        "        FASE 3: Fine-tuning e RAG para documentos\n",
        "            TÃ©cnicas de Fine-tuning + RAG para consulta de dados (protocolos mÃ©dicos do hospital + FAQ + Modelos)\n",
        "            Tratamento de dataset https://pubmedqa.github.io/ + Mock (protocolos mÃ©dicos do hospital + FAQ + Modelos)\n",
        "\n",
        " CriaÃ§Ã£o de assistente mÃ©dico com LangChain (âœ…)\n",
        "\n",
        "    [X] Utilizar o LangChain para:\n",
        "        Construir um pipeline que integre a LLM customizada\n",
        "        Realizar consultas em base de dados estruturadas (como prontuÃ¡rios e registros)\n",
        "        Contextualizar as respostas da LLM com informaÃ§Ãµes atualizadas do paciente\n",
        "    Aulas:\n",
        "        FASE 3: LangChain na prÃ¡tica\n",
        "            IteraÃ§Ã£o com LLMs\n",
        "        FASE 3: LangGraph\n",
        "            IteraÃ§Ã£o com LLMs usando workflows (nÃ³s)\n",
        "\n",
        " SeguranÃ§a e validaÃ§Ã£o (âœ…)\n",
        "\n",
        "    [X] Definir os limites de atuaÃ§Ã£o do assistente para evitar sugestÃµes imprÃ³prias (exemplo: nunca prescrever diretamente, sem a validaÃ§Ã£o humana)\n",
        "    Implementar logging detalhado para rastreamento e auditoria\n",
        "    Garantir explainability das respostas da LLM (exemplo: indicar a fonte da informaÃ§Ã£o utilizada na resposta)\n",
        "    Aulas:\n",
        "        FASE 3: IA: Guia de Prompts\n",
        "            Prompt engineering\n",
        "        6IADT - Guardrails e validaÃ§Ã£o\n",
        "            GravaÃ§Ã£o de aula (Zoom)  Senha: &7woyXRX\n",
        "\n",
        " OrganizaÃ§Ã£o do cÃ³digo (âœ…)\n",
        "\n",
        "    Projeto modularizado em Python\n",
        "    InstruÃ§Ãµes completas no README\n",
        "\n"
      ],
      "metadata": {
        "id": "zRgH8MEnHxRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9]{1,}\\.[0-9]{1,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.33.post1\" if v==\"2.9\" else \"0.0.32.post2\" if v==\"2.8\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2"
      ],
      "metadata": {
        "id": "2oL2NQoWOgpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive"
      ],
      "metadata": {
        "id": "PT1VbhM5cJT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "tafz--SuWEYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a69746-c276-4659-eb79-1f1ec6071e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "S4dnJT9_Rg_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "import torch\n",
        "import json\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "BLAZlQVZRPm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9b4ecb-9b2d-4736-d30d-c61a208c342b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definindo o modelo"
      ],
      "metadata": {
        "id": "6QF9ISMjQVlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_(4B).ipynb#scrollTo=-Xbb0cuLzwgf\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "model_id = \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\"\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_id,\n",
        "    max_seq_length,\n",
        "    load_in_4bit=load_in_4bit, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508,
          "referenced_widgets": [
            "bf81fe9fc8c84618953c049b2f83dc02",
            "53de8c5166334c48b43d5a79017be54f",
            "30e3a433c3e74b02bbb16173f6c012d9",
            "956b8f9b9ee5490385d348f343e3af3e",
            "2d8f852a346845fb9b0480e226c0327b",
            "3f0103f2f20942b091ab0aaa50796700",
            "748180851a8f45b5ab4b0195c987f530",
            "7a1383d8613448b991cae6316b0462b2",
            "49496bf5a59c4268b3dd41ec2beacf7e",
            "2e32055f7415477fa37185fce3f04c87",
            "58a199e728384c34a35d639adc09c5ce",
            "eda51823602147f59d0705e14f3d00b6",
            "aa50f8a0426942b3a0a25f0954aa3b4a",
            "f742772f9a644f22a059f61d2542e4a0",
            "ff8e0e2543c441aabbc72d0fa25c17f9",
            "9e9aa9ccd8a948859ebb1974f612d41b",
            "c4a2168401374439964b11517451ea2a",
            "7b820ee692874b2d92996cf9c6c170c6",
            "1553c22d7f0c42228cf0a5e6f16c0ff8",
            "df193bc8d17a48219d4e9175eadb45ef",
            "e4d43b2536d84049b53f376e7afe7124",
            "c627952f7767490d8060a2d61c9226f7",
            "e240168767a340e6a8db2df9be4c2deb",
            "1959fdd9341d4ed682abd862e0bb6930",
            "3a9a3ada6de24433becbf75a0f8bd5ed",
            "b9716fd08517424aac58f330767075d8",
            "87c1969254fd413795fdb1028dd86903",
            "22859f439e2545f581763dd0bb828e18",
            "a4f4844b8579449eb89d68606de864af",
            "f4422eac4fb944cd90811a3e68bb158e",
            "f9ab0fb10c6c46ef97b480117d29223f",
            "acf0e3c4f0074a53acc8b35d690f0253",
            "0212b5286aea4b6ba68018ed5635534d",
            "6f8a97f5f0484079bf32b393166f5ee2",
            "3519d7ff389f460fb752f07152ac197a",
            "a2a54c54fe754f3f8c2eba710823bbad",
            "1d34ee1e3cf14903b7606e0e7339b220",
            "2eb2c5ac671f4c049958ddf37ac26fa3",
            "9bfb753759e441d38c97d01010ec9834",
            "7602ae48f0794ad2be3806564a2a2870",
            "d4e149d6605f4e9f8c1583ee97627201",
            "91c74af92b054be58e0b7a91300f061d",
            "da382b9dca21421f9cb8b868db74471f",
            "026eb94218ab4b16aa287a1063ebfbcc",
            "80e0218db8c445b58433232c6b3f5ac2",
            "f2b51b897c0d4422b090ff2cb639f245",
            "a64650cb1af947f18247812ec551d50f",
            "e836602ff540439da7abf9ea4b6d9e42",
            "03dbbcadc39a49daa6b0b6641cf82a97",
            "2a0f731bd88242c7b8b071ce1cd86a2e",
            "d1226b417398410d9614291ebb9bad7c",
            "6ce249dd204849d894c8d2fd3bd3fbda",
            "8a42cbcfe7464bf3a684c2f4e564f0aa",
            "e7158c409c664a9a9902623f1d7c7a64",
            "c43363af368947a69c1a6992be538506",
            "201df50e38ed4ce6a5341f986dc20477",
            "e81af12001ec46b9b2dc43b3f8b5f825",
            "2d989b35622d486a9cc4fca1bc3c1e89",
            "d68fc62775634345b6770dcfc8b8c4a4",
            "69f7a72abcea4a44b6678c2810b1875f",
            "5c7f3c970bb7436983c46a6161ff3f52",
            "ced09c5f9d984044bc92aeb7e627b082",
            "b461576a133046f69d1840da9bdee867",
            "f462c82624a049d98361fe5222e19996",
            "b0ef8d5477c64aff81d91c5a4bff49cb",
            "eb2ad41d65904c9dbb25e067164aa44d",
            "129e96761d29410fa1938db968e9bdcb",
            "41583f047dd64ee5ac8b5a01caefd8c4",
            "66b4276366c640368eb1e340ca673035",
            "34f914bba73f49b0872769dba312448f",
            "ea39b2f441624e8da3c4d9f021c2ebd1",
            "2e4c45bbd65f48cda87fb07766fea20a",
            "3534be04322f4328aefb00069a4a2209",
            "8ea0236e873c4de1a16418c119fddb7c",
            "346aa7b0007444868631dd616e8bdb1a",
            "1175b3e504be4693a9dd176d739878bb",
            "47ffafdf16ad41ba8546b0b8e4484f1d",
            "500f252a169841ab8d522155f9083b69",
            "27135d26fd1e4f548e68ea5f63d89902",
            "98d0f44f3b994045a7826fcf163dfbf5",
            "60c7186cee394071af964ec4184ab5a8",
            "8edc07adc9c14bc6b5317d500d9373f5",
            "f8e471ec9ac94bdfa74980e878638962",
            "5b3dccda3b6e47adbf0f51fb44ade97a",
            "40283f7f1e8a454cae1a1b01e47215fe",
            "202655206e3a4785a0244966f6e4cd76",
            "d1aeb9095f7a403d8c8fc270a1e965fe",
            "de196026553d4942a2f510850db8c1bb",
            "fc7fc444dfa84f7aae6358bb880cb16c",
            "c3f4ccb79bac4b3eadafa13462f68918",
            "bd95cede21064bb68e15dfe61bff16fe",
            "f2dc7746107d4de4b486dafda3a3bbb4",
            "f41c72f8edde4bd3a8b6a2d446678196",
            "00e5866884dc41fda056ee0275c51872",
            "80480b99cc1f49bf84468964d1851e64",
            "de0dd6be26b64f65aa73e7ac27c793fe",
            "c7c658d7da014e4b96066c58eb1437e7",
            "53c37585342f4045b3b9db8aad74bca5",
            "740dc047e15741ada2da57e30ff264e7",
            "272c2913a0dd4df9b65ef99d63d9ab3d",
            "eb0c6d68bd6442ec9580d84fffd557bf",
            "044837584f15422e945092c8f9aa89cc",
            "0cd69bec2c7b4c1388fe4dd172302f33",
            "0274b569ffa542cc99a1c331d2a4be70",
            "9a75e85183fd4157bd716d2546d364ef",
            "71b600a894364017b208182b6bbb2802",
            "4f8b642965e442abad32ef0331a43114",
            "a75127a5579943e496008e22bd9ab1b9",
            "730bf1defd174d90898d15a29bba1146",
            "3535d9b4d8ed40dc99f09a98b028061a",
            "e7e4eb26045b4a91b78201702bd8986d",
            "2a851a76e7e14e8198ff738a9d0df83d",
            "514c19d9ba184fae82b2f467de65d7cf",
            "d2e2bf1af4b74b6299fca5e4705d851c",
            "b8015a279bb24d15bf334db158568cc4",
            "5b1d8b7e43c14d009141f7163a1d33a3",
            "7469e7944b6b4f1f95869c9435b88f4f",
            "10e4b02f053d4ace8c501f48f37bb9cd",
            "98cb72cde7884ec9bb0fb0959dc18deb",
            "65c54e4ca1bb4fe6bd848d09fa0a6b8c",
            "4007f8d58b6c4bd69bccbbe32d4e2ebd"
          ]
        },
        "id": "6kUea0ivQYM5",
        "outputId": "5548c60f-5ff0-434d-a29c-dd544ddd5e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.12.5: Fast Gemma3 patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
            "Unsloth: Gemma3 does not support SDPA - switching to fast eager.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.56G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf81fe9fc8c84618953c049b2f83dc02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eda51823602147f59d0705e14f3d00b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e240168767a340e6a8db2df9be4c2deb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f8a97f5f0484079bf32b393166f5ee2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80e0218db8c445b58433232c6b3f5ac2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "201df50e38ed4ce6a5341f986dc20477"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "129e96761d29410fa1938db968e9bdcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "500f252a169841ab8d522155f9083b69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc7fc444dfa84f7aae6358bb880cb16c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "272c2913a0dd4df9b65ef99d63d9ab3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7e4eb26045b4a91b78201702bd8986d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 8,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 8,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ],
      "metadata": {
        "id": "sp4fblzSTuGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021e9fe2-9ab1-4fb6-efee-d0830c66265a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Making `base_model.model.model.vision_tower.vision_model` require gradients\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formatando o dataset para fine-tunning"
      ],
      "metadata": {
        "id": "s5lbnl8XU0Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"gemma-3\",\n",
        ")\n",
        "\n",
        "def convert_to_conversation(sample, index):\n",
        "  convos = []\n",
        "  num_samples_in_batch = len(sample[\"QUESTION\"])\n",
        "\n",
        "  for i in range(num_samples_in_batch):\n",
        "    contexts_single = sample[\"CONTEXTS\"][i] if sample[\"CONTEXTS\"][i] else []\n",
        "    formatted_contexts = \" \".join(contexts_single)\n",
        "    labels_single = sample[\"LABELS\"][i] if sample[\"LABELS\"][i] else []\n",
        "    formatted_labels = \" \".join(labels_single)\n",
        "\n",
        "    convos.append([\n",
        "            {\n",
        "              'content': f\"\"\"\n",
        "              ## CONTEXT\n",
        "              {formatted_contexts}\n",
        "\n",
        "\n",
        "              ## QUESTION\n",
        "              {sample[\"QUESTION\"][i]}\n",
        "\n",
        "              \"\"\",\n",
        "              'role': 'user'\n",
        "            },\n",
        "            {\n",
        "              'content': f\"\"\"\n",
        "              ## ANSWER\n",
        "              {sample[\"final_decision\"][i]}. {sample[\"LONG_ANSWER\"][i]}\n",
        "\n",
        "              ## METADATA\n",
        "\n",
        "              ### YEAR\n",
        "              {sample[\"YEAR\"][i]}\n",
        "\n",
        "              ### LABEL\n",
        "              {formatted_labels}\n",
        "              \"\"\",\n",
        "              'role': 'assistant'\n",
        "            }\n",
        "          ])\n",
        "\n",
        "  texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False).removeprefix('<bos>') for convo in convos]\n",
        "  return { \"text\" : texts, }\n",
        "\n",
        "\n",
        "OUTPUT_PATH_DATASET = \"/content/drive/MyDrive/AI/tech challenge/ori_pqal.json\"\n",
        "\n",
        "# Load the JSON file manually as it's a dictionary of dictionaries\n",
        "with open(OUTPUT_PATH_DATASET, \"r\") as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "# Convert the dictionary of records into a list of records\n",
        "dataset_list = list(raw_data.values())\n",
        "\n",
        "# Create a Dataset object from the list\n",
        "dataset = Dataset.from_list(dataset_list)\n",
        "\n",
        "# Now, apply the map function to the correctly loaded dataset\n",
        "dataset = dataset.map(convert_to_conversation, batched=True, with_indices=True)\n",
        "\n",
        "print('RESPONSE FINAL',  dataset[0]['text'])\n"
      ],
      "metadata": {
        "id": "SymGyBhHU4C4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "776be1c395064d699bf3f692367084b9",
            "f7a088ea9c334e52a78c59ead020e2fc",
            "b922cbf2d9564335b91f339bbe6ab6df",
            "e085a4b1947f4cbeb649532259f82830",
            "01dc0215552a4a66a656c70f1d43e6bb",
            "e4a7acc0102e4a2ebab425e71a879180",
            "f8e0f91564c0429ab39bce79901e3f90",
            "e18c01c5cbd34618bccc7d3e640742c6",
            "41ac2f1c14a940c08f336c9e1de0b437",
            "e035e004eea34e05848f338609addbbc",
            "0d6f6d0493f14a19afc33c07e8812cf2"
          ]
        },
        "outputId": "37cdfb9f-27fc-4abe-9e91-3ab21a1a2f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "776be1c395064d699bf3f692367084b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPONSE FINAL <start_of_turn>user\n",
            "## CONTEXT\n",
            "              Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature. The role of mitochondria during PCD has been recognized in animals; however, it has been less studied during PCD in plants. The following paper elucidates the role of mitochondrial dynamics during developmentally regulated PCD in vivo in A. madagascariensis. A single areole within a window stage leaf (PCD is occurring) was divided into three areas based on the progression of PCD; cells that will not undergo PCD (NPCD), cells in early stages of PCD (EPCD), and cells in late stages of PCD (LPCD). Window stage leaves were stained with the mitochondrial dye MitoTracker Red CMXRos and examined. Mitochondrial dynamics were delineated into four categories (M1-M4) based on characteristics including distribution, motility, and membrane potential (Î”Î¨m). A TUNEL assay showed fragmented nDNA in a gradient over these mitochondrial stages. Chloroplasts and transvacuolar strands were also examined using live cell imaging. The possible importance of mitochondrial permeability transition pore (PTP) formation during PCD was indirectly examined via in vivo cyclosporine A (CsA) treatment. This treatment resulted in lace plant leaves with a significantly lower number of perforations compared to controls, and that displayed mitochondrial dynamics similar to that of non-PCD cells.\n",
            "\n",
            "\n",
            "              ## QUESTION\n",
            "              Do mitochondria play a role in remodelling lace plant leaves during programmed cell death?<end_of_turn>\n",
            "<start_of_turn>model\n",
            "## ANSWER\n",
            "              yes. Results depicted mitochondrial dynamics in vivo as PCD progresses within the lace plant, and highlight the correlation of this organelle with other organelles during developmental PCD. To the best of our knowledge, this is the first report of mitochondria and chloroplasts moving on transvacuolar strands to form a ring structure surrounding the nucleus during developmental PCD. Also, for the first time, we have shown the feasibility for the use of CsA in a whole plant system. Overall, our findings implicate the mitochondria as playing a critical and early role in developmentally regulated PCD in the lace plant.\n",
            "\n",
            "              ## METADATA\n",
            "\n",
            "              ### YEAR\n",
            "              2011\n",
            "\n",
            "              ### LABEL\n",
            "              BACKGROUND RESULTS<end_of_turn>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    eval_dataset = None, # Can set up evaluation!\n",
        "    args = SFTConfig(\n",
        "        dataset_text_field = \"text\",\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 30,\n",
        "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.001,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        report_to = \"none\", # Use TrackIO/WandB etc\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "RKEU30Ffgy6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "550df652b3214eeea4334d1b889b2656",
            "3041a5e2b2194b159c9a4909bd7d37b0",
            "705ac71927e14f7c8c78e488ffcfa4f0",
            "847c377a49a343b3a8a759a27a25f994",
            "c6894c09ee25497f8fda967de81607bc",
            "8ebb4b19cb89476d88ccd781d8b8eac7",
            "91793f849ce4447885db672d823c5922",
            "2fb0d0ad26204944a2da7d6cf247e347",
            "b4271f77a7d243e78d84b4f06b1e78f5",
            "6bd71c2e9aa64721a06ed12edd98c167",
            "bc619a34778942b2b9e043cf282c6531"
          ]
        },
        "outputId": "a35b8bb6-0156-48b0-99c1-86bc7568d97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Switching to float32 training since model cannot work with float16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "550df652b3214eeea4334d1b889b2656"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melhoria do fine tunning, reduzindo a perda nas respostas das roles users."
      ],
      "metadata": {
        "id": "rB0gOceKjU6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<start_of_turn>user\\n\",\n",
        "    response_part = \"<start_of_turn>model\\n\",\n",
        ")"
      ],
      "metadata": {
        "id": "saTRvfoljURi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7ca34686610d435480d634a2914ec48b",
            "d06e5f0e0a97494d816da7a2d2290338",
            "559256c1e4a24deb939c557ab5968a05",
            "a92ecb8e1bc442c0ae7b42bb16662645",
            "bcd0451bb56842399ef6854cf8aa5c55",
            "0cadbd3816d248579105fdcf4d6692d9",
            "cf48a443bf964ae4a79bc68ad2adb3a2",
            "c9e1c49195c54efc94154f796e45a1eb",
            "a1ab06887830417ab97d8c030d69a887",
            "22e5d045cecc464bb0536ecf0723afd4",
            "92244942905b41c78de604f5105f3687"
          ]
        },
        "outputId": "e66b5206-cfad-4168-f94c-28a2fcfb9c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=6):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ca34686610d435480d634a2914ec48b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "gA6-4q4eLq5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e18d5928-8a38-48c9-d23d-3facc2bc0e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1 | Total steps = 30\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 16,394,240 of 4,316,473,712 (0.38% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 03:40, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.680400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.510900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.453200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.392800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.960300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.873600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.651400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.312400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.358000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.020100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.971800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.998500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.718800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.872800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.586000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.664400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.363300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.633200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.160300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.325100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.303000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.190400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.325000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.454700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.242600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.753400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.201300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.405600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.321900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.297500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvar modelo"
      ],
      "metadata": {
        "id": "fr67dZX9L5-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#local\n",
        "# model.save_pretrained(\"/content/drive/MyDrive/AI/tech challenge/modelos/lora_model\")\n",
        "# tokenizer.save_pretrained(\"/content/drive/MyDrive/AI/tech challenge/modelos/lora_model\")\n",
        "\n",
        "#hugginface\n",
        "model.push_to_hub(\"gerson-analista/gemma-3-4b-lora_model\", token = userdata.get('HF_TOKEN')) # Online saving\n",
        "tokenizer.push_to_hub(\"gerson-analista/gemma-3-4b-lora_model\", token = userdata.get('HF_TOKEN')) # Online saving"
      ],
      "metadata": {
        "id": "bgfQJTpDL4Io",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325,
          "referenced_widgets": [
            "68619632a2364597a43cfdaca7c5a57e",
            "88eb07bdc84440d9b51ff8c5ce841bb8",
            "a9de8359dc3e4fbf897e5e3c4db3f63e",
            "98bf18b6fc744cd9a575c4bff12bea1f",
            "d89754a67c894367b57659fbc432177a",
            "61cdb1769e354b239ba0808d2d793eda",
            "1f7e787e2df74d128f4a494a66907d7b",
            "bdfb7e84a42843d79c2b14b97fe19e7b",
            "97b5a7c3f7c24d80838323d6faf3c9f6",
            "23186dfc2ffc4e489945e6967d8e0d5b",
            "a967f04f428b46118df1aa0f45030e89",
            "003a4c4ac8fc4ed6bcb996c490b4f5cc",
            "9d013623f906454aa2d9459bc8a63837",
            "ccd929a114164a02bcc79c6e6c59833b",
            "a84d4e15db4b41efbb8f3ea5dd768b48",
            "95abb801284b432eab9e00c64a4f405c",
            "f1bc97c824704f69bea1387f7fd497a3",
            "1349408480fc4e17b99986cf64994a5a",
            "8ba797e295bf49e0a5020f0800b46c5a",
            "adfdd5c51d354b64aec1bb2fa1ba6d3a",
            "98cd459beadb4fd6b4dc00025cbfc43c",
            "04d2ca6295744a0594ddd1ea903c6577",
            "70392e23b99a4e7b8d6b6e91fa04e69b",
            "58bad401450d43e19655c0ee92d9e3aa",
            "7642ca5c5497457c9fc02b55cdd4ad10",
            "43e8a861b0a7488bad1f5defb9617176",
            "2a6b0a3ce1d447f2be76b4339a8fa404",
            "3392c6c95f134bdd919e1dfbc6450a5b",
            "5aa574766179498e865817133a04aaac",
            "41576e17413d4337b31eb6bb3ece3e6f",
            "5e747c3f7cf441039a85f65c5b730460",
            "c811140aee8d4e7b9c215ba076bb06b9",
            "01850a142999497686f4c6e3b5536c23",
            "7b75224164324fe2ac8a4ac7a7339938",
            "2ef5eafebfd74b52b97968ee7b9f5b32",
            "b2dbb853b40a45f88bea1dd8172af190",
            "1a643ea90d2e442888e5d2960cac647c",
            "a8e80901bf94432fa11a135ec241e4f9",
            "6a438d3af2d74d79b3b9bf08d35282e8",
            "62afa8d9edab42deae15b0c4b22fc6ef",
            "4653bdbd498e4946945d7573130cbdc4",
            "f917cfaaa5a647dda9bdcfc8db927e19",
            "a3b507d1a7b64f318be2f7b3618c8410",
            "cc9024da5737477680ae4c375908e700",
            "371356dc12a74ff2ac6038e300a8f8e9",
            "6fa5025cb85d4f3581c2ec3904958c4f",
            "3241f6120c9040698dd380dd933ccc50",
            "6765ba0fd9054a289dcb5397f6df134d",
            "c83c46fc18444d59a696eb9b9e92f3a7",
            "d0e32879f94a4501a4ff6f0d09dbf98a",
            "99ebe647891242008e0e497c9d4ef73b",
            "0f16ee0a7c284ec99e77d214002a2667",
            "9059d55c1dc748a09dd214feed17fec2",
            "878797c467104244826f3f1804277c6b",
            "747cf4573f984ee6ba9ea78c5601264c",
            "4c4ea482ba614e93b8241e4796687289",
            "b4d9263ebbda49169b45a4a1099cd34d",
            "fd165b83dfb3467ca646a9cb043c9be1",
            "e2a0dfd8d1e94d06a7448a45e4068ecb",
            "341d9eb6df584feaba2a6c2ebec4439c",
            "b2a915aaa2414dc2ac41c6482f46c84b",
            "c3e8f1f7109347b4a52335f49e073c58",
            "53c5d1a35fc54f07bc9c3c845b2d05ad",
            "478155317d7a4948beb447ef7ab24df9",
            "31104329498646cabdb223102dcb86c2",
            "2364f081e08e4e7f837c8aa33b7e4470",
            "6f64ae32980e4b818a35c294e40a808c",
            "d2c362b138be454d88b5b750a7c767b9",
            "902401042e234feea16d4ebb2968b269",
            "223162cbd84042679a4d2fb50591916c",
            "b56a4082cecc4684934c9d683510d60b",
            "bd4575193122469c9b65805fcbe84c94",
            "d4516cb87df94bba951b6fd05e06a400",
            "6066ef7a52394a64b9c2575b4ca280e4",
            "bdaac7de85a94e519ea439f355cb8ab0",
            "4b656a3487e14950a2fe42a8f142fae8",
            "b867210d4c3a4c538f6001838d8d694c",
            "8c1eda165baf4846a78f0f42cb160312",
            "cdf5b91c087d41f5b1c6c4557966a494",
            "e6849c36230f4c18b64bb4e44a8f804b",
            "c13c31fc4f04483f92491a78077088fd",
            "4f946476c13f4e5ca7dd1324fddf9232",
            "034a6c8e075c41b0b193aebee8526975",
            "e495517077bc4043bc2f74e477c9a2b6",
            "80ca34dcf7154b969e836410e420528a",
            "8037fb744971498c88e025fc4ebf5a54",
            "c43c02f007cb40bf81412b665a030a3a",
            "1cced0a9d5ca433aa74b4451e954a5f0"
          ]
        },
        "outputId": "42eee726-fcd4-4908-e694-d50fd7332e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/606 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68619632a2364597a43cfdaca7c5a57e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "003a4c4ac8fc4ed6bcb996c490b4f5cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70392e23b99a4e7b8d6b6e91fa04e69b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...adapter_model.safetensors:   0%|          | 17.0kB / 65.7MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b75224164324fe2ac8a4ac7a7339938"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to https://huggingface.co/gerson-analista/gemma-3-4b-lora_model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "371356dc12a74ff2ac6038e300a8f8e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c4ea482ba614e93b8241e4796687289"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...mpuyuvv048/tokenizer.json: 100%|##########| 33.4MB / 33.4MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f64ae32980e4b818a35c294e40a808c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...puyuvv048/tokenizer.model: 100%|##########| 4.69MB / 4.69MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c1eda165baf4846a78f0f42cb160312"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vamos carregar do huggingface, caso deseje mudar hÃ¡ a necessidade de ajustar o cÃ³digo acima"
      ],
      "metadata": {
        "id": "AKCxq29KkIcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    #model_name = \"/content/drive/MyDrive/AI/tech challenge/modelos/lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "    model_name = \"gerson-analista/gemma-3-4b-lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "FastLanguageModel.for_inference(model)"
      ],
      "metadata": {
        "id": "eRoxA2oAWxA5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f0d2e94b62ca4605858df8ef6ad0e48e",
            "6795f07fd9e84e489060459444a64e0d",
            "f9dc66119b1d4943b87e1cc9a4127790",
            "183e4e0e19b746b5bb70f6165c8bd246",
            "6790a07f5b614d4f9e9cbf50285b6b5a",
            "5c92a5ebe3c349b5888e299dfc31fc1f",
            "22797af53be142b582a59b2e24b274d8",
            "c4699f3080a2455e84ff4e6c6e4106d7",
            "80a9926bd64b4738a11f5132097dcbda",
            "8205a87c832d46688b752942adb7ae96",
            "d49bb032eaec472ea37877cb9f6271f3"
          ]
        },
        "outputId": "09704d38-2da3-4ede-c449-f15489cf8bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.12.5: Fast Gemma3 patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
            "Unsloth: Gemma3 does not support SDPA - switching to fast eager.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/65.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0d2e94b62ca4605858df8ef6ad0e48e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Gemma3ForConditionalGeneration(\n",
              "      (model): Gemma3Model(\n",
              "        (vision_tower): SiglipVisionModel(\n",
              "          (vision_model): SiglipVisionTransformer(\n",
              "            (embeddings): SiglipVisionEmbeddings(\n",
              "              (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
              "              (position_embedding): Embedding(4096, 1152)\n",
              "            )\n",
              "            (encoder): SiglipEncoder(\n",
              "              (layers): ModuleList(\n",
              "                (0-26): 27 x SiglipEncoderLayer(\n",
              "                  (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "                  (self_attn): SiglipAttention(\n",
              "                    (k_proj): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=1152, out_features=1152, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Identity()\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=1152, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=1152, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                      (lora_magnitude_vector): ModuleDict()\n",
              "                    )\n",
              "                    (v_proj): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=1152, out_features=1152, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Identity()\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=1152, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=1152, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                      (lora_magnitude_vector): ModuleDict()\n",
              "                    )\n",
              "                    (q_proj): lora.Linear(\n",
              "                      (base_layer): Linear(in_features=1152, out_features=1152, bias=True)\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Identity()\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=1152, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=1152, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                      (lora_magnitude_vector): ModuleDict()\n",
              "                    )\n",
              "                    (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
              "                  )\n",
              "                  (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "                  (mlp): SiglipMLP(\n",
              "                    (activation_fn): PytorchGELUTanh()\n",
              "                    (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
              "                    (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (multi_modal_projector): Gemma3MultiModalProjector(\n",
              "          (mm_soft_emb_norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
              "          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        )\n",
              "        (language_model): Gemma3TextModel(\n",
              "          (embed_tokens): Gemma3TextScaledWordEmbedding(262208, 2560, padding_idx=0)\n",
              "          (layers): ModuleList(\n",
              "            (0-1): 2 x Gemma3DecoderLayer(\n",
              "              (self_attn): Gemma3Attention(\n",
              "                (q_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2048, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (k_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (o_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2048, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "              )\n",
              "              (mlp): Gemma3MLP(\n",
              "                (gate_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=10240, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (up_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=10240, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (down_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=10240, out_features=2560, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=10240, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act_fn): PytorchGELUTanh()\n",
              "              )\n",
              "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "            )\n",
              "            (2): Gemma3DecoderLayer(\n",
              "              (self_attn): Gemma3Attention(\n",
              "                (q_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2560, out_features=2048, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2048, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (k_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (o_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2048, out_features=2560, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2048, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "              )\n",
              "              (mlp): Gemma3MLP(\n",
              "                (gate_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=10240, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (up_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=10240, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (down_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=10240, out_features=2560, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=10240, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act_fn): PytorchGELUTanh()\n",
              "              )\n",
              "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "            )\n",
              "            (3-5): 3 x Gemma3DecoderLayer(\n",
              "              (self_attn): Gemma3Attention(\n",
              "                (q_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2048, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (k_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (o_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2048, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "              )\n",
              "              (mlp): Gemma3MLP(\n",
              "                (gate_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=10240, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (up_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=10240, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (down_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=10240, out_features=2560, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=10240, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act_fn): PytorchGELUTanh()\n",
              "              )\n",
              "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "            )\n",
              "            (6-33): 28 x Gemma3DecoderLayer(\n",
              "              (self_attn): Gemma3Attention(\n",
              "                (q_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2048, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (k_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (o_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2048, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "              )\n",
              "              (mlp): Gemma3MLP(\n",
              "                (gate_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=10240, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (up_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=10240, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (down_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=10240, out_features=2560, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Identity()\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=10240, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act_fn): PytorchGELUTanh()\n",
              "              )\n",
              "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "            )\n",
              "          )\n",
              "          (norm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
              "          (rotary_emb): Gemma3RotaryEmbedding()\n",
              "          (rotary_emb_local): Gemma3RotaryEmbedding()\n",
              "        )\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2560, out_features=262208, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando o modelo prÃ©-treinado\n"
      ],
      "metadata": {
        "id": "SO3le_sKcMt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [{\"type\" : \"text\", \"text\" : \"My patient has high blood pressure, does it increases the chance of heart attack?\",}]\n",
        "}]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    tokenize = True,\n",
        "    return_tensors = \"pt\",\n",
        "    return_dict = True,\n",
        ")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "_ = model.generate(\n",
        "    **inputs.to(\"cuda\"),\n",
        "    max_new_tokens = 64, # Increase for longer outputs!\n",
        "    # Recommended Gemma-3 settings!\n",
        "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
        ")"
      ],
      "metadata": {
        "id": "fRqjbCnfj3vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee7f3f9-06c5-4126-da53-88a1815664d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "youâ€™re asking a very important and crucial question about your patient, Iâ€™m glad youâ€™re asking this about how high blood pressure will affect them.\n",
            "\n",
            "yes, that is a good and relevant question to ask. you will want to provide this information for your patient so that they will understand and have a chance\n"
          ]
        }
      ]
    }
  ]
}